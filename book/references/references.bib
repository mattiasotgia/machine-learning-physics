@book{aggarwal2018,
  title = {Neural {{Networks}} and {{Deep Learning}}: {{A Textbook}}},
  shorttitle = {Neural {{Networks}} and {{Deep Learning}}},
  author = {Aggarwal, Charu C.},
  year = {2018},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-94463-0},
  urldate = {2024-02-19},
  isbn = {978-3-319-94462-3 978-3-319-94463-0},
  langid = {english},
  keywords = {Adam,autoencoder,backpropagation,conjugate gradient-descent,Convolutional Neural Networks,Deep Learning,deep reinforcement learning,dropout,generative adversarial networks,Kohonean self-organizaing map,logistic regression,Machine Learning,Neural networks,perceptron,pretraining,Radial Basis Function Networks,Recurrent Neural Networks,Restricted Boltzmann Machines,RMSProp,word2vec}
}

@book{cowan1998a,
  title = {Statistical {{Data Analysis}}},
  author = {Cowan, Glen and Cowan, Glen},
  year = {1998},
  month = mar,
  publisher = {{Oxford University Press}},
  address = {{Oxford, New York}},
  abstract = {This book is a guide to the practical application of statistics in data analysis as typically encountered in the physical sciences. It is primarily addressed at students and professionals who need to draw quantitative conclusions from experimental data. Although most of the examples are taken from particle physics, the material is presented in a sufficiently general way as to be useful to people from most branches of the physical sciences. The first part of the book describes the basic tools of data analysis: concepts of probability and random variables, Monte Carlo techniques, statistical tests, and methods of parameter estimation. The last three chapters are somewhat more specialized than those preceding, covering interval estimation, characteristic functions, and the problem of correcting distributions for the effects of measurement errors (unfolding).                                                        ,                This book is a guide to the practical application of statistics in data analysis as typically encountered in the physical sciences. It is primarily addressed at students and professionals who need to draw quantitative conclusions from experimental data. Although most of the examples are taken from particle physics, the material is presented in a sufficiently general way as to be useful to people from most branches of the physical sciences. The first part of the book describes the basic tools of data analysis: concepts of probability and random variables, Monte Carlo techniques, statistical tests, and methods of parameter estimation. The last three chapters are somewhat more specialized than those preceding, covering interval estimation, characteristic functions, and the problem of correcting distributions for the effects of measurement errors (unfolding).},
  isbn = {978-0-19-850155-8},
  file = {/Users/massimosotgia/Zotero/storage/NUBHNAIL/statistical-data-analysis-9780198501558.html}
}

@book{goodfellow2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {{MIT press}},
  urldate = {2024-02-19},
  file = {/Users/massimosotgia/Zotero/storage/SP7V4L8E/Goodfellow et al. - 2016 - Deep learning.pdf}
}

@book{hastie2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-84858-7},
  urldate = {2024-02-19},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  keywords = {Averaging,Boosting,classification,clustering,data mining,machine learning,Projection pursuit,Random Forest,supervised learning,Support Vector Machine,unsupervised learning},
  file = {/Users/massimosotgia/Zotero/storage/HWVR7M5S/Hastie et al. - 2009 - The Elements of Statistical Learning.pdf}
}

@book{lista2017a,
  title = {Statistical {{Methods}} for {{Data Analysis}} in {{Particle Physics}}},
  author = {Lista, Luca},
  year = {2017},
  series = {Lecture {{Notes}} in {{Physics}}},
  volume = {941},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-62840-0},
  urldate = {2024-02-19},
  isbn = {978-3-319-62839-4 978-3-319-62840-0},
  langid = {english},
  keywords = {Bayesian Versus Frequentist Probability Theory,Data Analysis in High Energy Physics,Experimental Particle Physics and Data Analysis,Hypothesis Testing and Discovery-based Science,Look-elsewhere effect,Modified Frequentist Approach,Parameter Estimation and Uncertainties,Statistics Textbook for Particle Physics},
  file = {/Users/massimosotgia/Zotero/storage/HJKLDVHY/Lista - 2017 - Statistical Methods for Data Analysis in Particle .pdf}
}

@misc{plehn2022,
  title = {Modern {{Machine Learning}} for {{LHC Physicists}}},
  author = {Plehn, Tilman and Butter, Anja and Dillon, Barry and Krause, Claudius},
  year = {2022},
  month = nov,
  number = {arXiv:2211.01421},
  eprint = {2211.01421},
  primaryclass = {hep-ph},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2211.01421},
  urldate = {2024-02-19},
  abstract = {Modern machine learning is transforming particle physics, faster than we can follow, and bullying its way into our numerical tool box. For young researchers it is crucial to stay on top of this development, which means applying cutting-edge methods and tools to the full range of LHC physics problems. These lecture notes are meant to lead students with basic knowledge of particle physics and significant enthusiasm for machine learning to relevant applications as fast as possible. They start with an LHC-specific motivation and a non-standard introduction to neural networks and then cover classification, unsupervised classification, generative networks, and inverse problems. Two themes defining much of the discussion are well-defined loss functions reflecting the problem at hand and uncertainty-aware networks. As part of the applications, the notes include some aspects of theoretical LHC physics. All examples are chosen from particle physics publications of the last few years. Given that these notes will be outdated already at the time of submission, the week of ML4Jets 2022, they will be updated frequently.},
  archiveprefix = {arxiv},
  keywords = {High Energy Physics - Phenomenology},
  file = {/Users/massimosotgia/Zotero/storage/A3UBAL5J/Plehn et al. - 2022 - Modern Machine Learning for LHC Physicists.pdf;/Users/massimosotgia/Zotero/storage/WJHSL9C2/2211.html}
}

@article{rosasco2017,
  title = {Introductory {{Machine Learning Notes1}}},
  author = {Rosasco, Lorenzo},
  year = {2017},
  journal = {University of Genoa ML},
  urldate = {2024-02-19},
  file = {/Users/massimosotgia/Zotero/storage/8TJS6C76/Rosasco - 2017 - Introductory Machine Learning Notes1.pdf}
}
